{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLB3I4FKZ5Lr"
      },
      "source": [
        "# Fine-tuning BERT (and friends) for multi-label text classification\n",
        "The original code is from https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\n",
        "\n",
        "## Set-up environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U accelerate\n",
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "OAuyUm_jh8KF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wxY3x-ZZz8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b40cce-78c1-447a-8e4d-a86785158414"
      },
      "source": [
        "!pip install -q transformers datasets"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Uzxs-1M1HVQ0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/FACT-GPT dataset.csv').rename(columns={'Unnamed: 0': 'index'})"
      ],
      "metadata": {
        "id": "-KVldWYM86-S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syn_df = df[['claim', 'generated_entail_tweet_gpt-4', 'generated_contradict_tweet_gpt-4', 'generated_neutral_tweet_gpt-4']]\n",
        "\n",
        "# Reshape the DataFrame\n",
        "syn_df = syn_df.melt(id_vars='claim', var_name='label', value_name='tweet')\n",
        "\n",
        "# Replace the label names\n",
        "syn_df['label'] = syn_df['label'].replace({'generated_entail_tweet_gpt-4': 'ENTAILMENT',\n",
        "                                           'generated_contradict_tweet_gpt-4': 'CONTRADICTION',\n",
        "                                           'generated_neutral_tweet_gpt-4': 'NEUTRAL'})\n",
        "\n",
        "syn_df.reset_index(inplace=True)\n",
        "\n",
        "column_to_evaluate = 'label'\n",
        "\n",
        "# Add new columns\n",
        "syn_df['ENTAILMENT'] = syn_df[column_to_evaluate] == \"ENTAILMENT\"\n",
        "syn_df['CONTRADICTION'] = syn_df[column_to_evaluate] == \"CONTRADICTION\"\n",
        "syn_df['NEUTRAL'] = syn_df[column_to_evaluate] == \"NEUTRAL\"\n",
        "\n",
        "# Drop the original column\n",
        "syn_df.drop(columns=[column_to_evaluate], inplace=True)\n",
        "\n",
        "# Reorder columns to the desired order\n",
        "syn_df = syn_df[['index', 'tweet', 'claim', 'ENTAILMENT', 'NEUTRAL', 'CONTRADICTION']]\n",
        "syn_df"
      ],
      "metadata": {
        "id": "ja2kwCwBzbQV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_to_evaluate = 'Mturk_1'\n",
        "\n",
        "# Assuming df is your existing DataFrame\n",
        "new_df = df[['index', 'tweet', 'claim', column_to_evaluate]].copy()\n",
        "\n",
        "# Add new columns based on the value of 'entailment_few_shot_gpt-3_cleaned'\n",
        "new_df['ENTAILMENT'] = new_df[column_to_evaluate] == \"ENTAILMENT\"\n",
        "new_df['CONTRADICTION'] = new_df[column_to_evaluate] == \"CONTRADICTION\"\n",
        "new_df['NEUTRAL'] = new_df[column_to_evaluate] == \"NEUTRAL\"\n",
        "\n",
        "# Drop the original 'entailment_few_shot_gpt-3_cleaned' column if you wish\n",
        "new_df.drop(columns=[column_to_evaluate], inplace=True)\n",
        "\n",
        "# Reorder columns to the desired order\n",
        "new_df = new_df[['index', 'tweet', 'claim', 'ENTAILMENT', 'NEUTRAL', 'CONTRADICTION']]\n",
        "new_df"
      ],
      "metadata": {
        "id": "SzVsuH8LP8zK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIH9NP0MZ6-O"
      },
      "source": [
        "## Load dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd1LiXGjZ420"
      },
      "source": [
        "from datasets import Dataset\n",
        "import datasets"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the synthetic data into 80% training, 20% validation\n",
        "train_df, valid_df = train_test_split(syn_df, test_size=0.2, random_state=42)\n",
        "test_df = new_df"
      ],
      "metadata": {
        "id": "Li6KgxbkIYOl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.reset_index(drop=True, inplace=True)\n",
        "valid_df.reset_index(drop=True, inplace=True)\n",
        "test_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "sGrwA_E-MzMu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.DatasetDict({'train': Dataset.from_pandas(train_df),\n",
        "                                'valid': Dataset.from_pandas(valid_df),\n",
        "                                 'test': Dataset.from_pandas(test_df)})"
      ],
      "metadata": {
        "id": "2bVXSET1IMUh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5vZhQpvkE8s"
      },
      "source": [
        "labels = [label for label in dataset['train'].features.keys() if label not in ['index', 'tweet', 'claim']]\n",
        "id2label = {idx:label for idx, label in enumerate(labels)}\n",
        "label2id = {label:idx for idx, label in enumerate(labels)}\n",
        "labels"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ3Teyjmank2"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess_data(examples):\n",
        "    # Take a batch of texts and claims\n",
        "    text = examples[\"tweet\"]\n",
        "    claims = examples[\"claim\"]\n",
        "    # Concatenate them with the [SEP] token in between\n",
        "    combined_texts = [t + \" [SEP] \" + c for t, c in zip(text, claims)]\n",
        "    # Encode them\n",
        "    encoding = tokenizer(combined_texts, padding=\"max_length\", truncation=True, max_length=512)\n",
        "    # Add labels (your existing code here, assuming `labels` is defined elsewhere in your code)\n",
        "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
        "    labels_matrix = np.zeros((len(text), len(labels)))\n",
        "    for idx, label in enumerate(labels):\n",
        "        labels_matrix[:, idx] = labels_batch[label]\n",
        "    encoding[\"labels\"] = labels_matrix.tolist()\n",
        "    return encoding\n"
      ],
      "metadata": {
        "id": "g0xjw4-1Jy63"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4ENBTdulBEI"
      },
      "source": [
        "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0enAb0W9o25W"
      },
      "source": [
        "example = encoded_dataset['train'][1]\n",
        "print(example.keys())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0McCtJ8HRJY"
      },
      "source": [
        "tokenizer.decode(example['input_ids'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdIvj6WjHeZQ"
      },
      "source": [
        "example['labels']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4Dx95t2o6N9"
      },
      "source": [
        "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk6Cq9duKBkA"
      },
      "source": [
        "encoded_dataset.set_format(\"torch\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5qSmCgWefWs"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XPL1Z_RegBF"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                           problem_type=\"multi_label_classification\",\n",
        "                                                           num_labels=len(labels),\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjJGEXShp7te"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "797b2WHJqUgZ"
      },
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from transformers import EvalPrediction\n",
        "import torch\n",
        "\n",
        "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    # return as dictionary\n",
        "    metrics = {'f1': f1_micro_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'accuracy': accuracy}\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions,\n",
        "            tuple) else p.predictions\n",
        "    result = multi_label_metrics(\n",
        "        predictions=preds,\n",
        "        labels=p.label_ids)\n",
        "    return result"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxNo4_TsvzDm"
      },
      "source": [
        "Let's verify a batch as well as a forward pass:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IlOgGiojuWwG",
        "outputId": "b2c38463-73e0-4302-e1d7-8b1587af62e2"
      },
      "source": [
        "encoded_dataset['train'][0]['labels'].type()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y41Kre_jvD7x"
      },
      "source": [
        "encoded_dataset['train']['input_ids'][0]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxWcnZ8ku12V"
      },
      "source": [
        "#forward pass\n",
        "input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0)\n",
        "attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
        "\n",
        "outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n",
        "outputs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-X2brZcv0X6"
      },
      "source": [
        "Let's start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chq_3nUz73ib"
      },
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "batch_size = 8\n",
        "metric_name = \"f1\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"bert-finetuned-sem_eval-english\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        "    logging_steps=100\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"valid\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXmFds8js6P8"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiloh9eMK91o"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.evaluate(encoded_dataset[\"test\"])\n",
        "predictions, label_ids, metrics = trainer.predict(encoded_dataset[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "S3UznLpHPQJw",
        "outputId": "0da51ba6-4e32-4a59-aa88-85ff8276ba94"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Apply softmax to get probabilities\n",
        "probabilities = np.exp(predictions) / np.sum(np.exp(predictions), axis=1, keepdims=True)\n",
        "\n",
        "# Get the class that has the maximum probability\n",
        "predicted_classes = np.argmax(probabilities, axis=1)"
      ],
      "metadata": {
        "id": "PFsMqCdxThkt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = [id2label[idx] for idx in predicted_classes]\n",
        "y_pred = predicted_labels"
      ],
      "metadata": {
        "id": "3TKmWsosV6EQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the pickled random_aggregated_mturks list\n",
        "pickle_file_path = '/content/drive/MyDrive/FACT-GPT eval tiebreak.pkl'\n",
        "with open(pickle_file_path, 'rb') as f:\n",
        "    random_aggregated_mturks = pickle.load(f)"
      ],
      "metadata": {
        "id": "JtMw0zbSI5hP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "ev = []\n",
        "for i in range(1000):\n",
        "    ev += random_aggregated_mturks[i]"
      ],
      "metadata": {
        "id": "_uOK_TJnVuY3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_true is your ground truth labels and y_pred is the predicted labels from your model\n",
        "report = classification_report(ev, y_pred * 1000, target_names=['CONTRADICTION', 'ENTAILMENT', 'NEUTRAL'])\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcWKQ4KrUxzU",
        "outputId": "8312898a-494f-4225-cd1f-455526dd7fc9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "CONTRADICTION       0.13      0.52      0.21    100502\n",
            "   ENTAILMENT       0.65      0.65      0.65    668891\n",
            "      NEUTRAL       0.59      0.20      0.30    455607\n",
            "\n",
            "     accuracy                           0.47   1225000\n",
            "    macro avg       0.46      0.46      0.39   1225000\n",
            " weighted avg       0.59      0.47      0.48   1225000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}