{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning Llama-2 models\n",
        "- Initially fine-tuned via USC HPC clusters\n",
        "- Possible to fine-tune on A100 or V100 with Google Colab Pro subscription or above"
      ],
      "metadata": {
        "id": "ivLYNWTn2sLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5-AwYQ653Mqw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Change directory\n",
        "os.chdir('/content/drive/MyDrive/Finetuning')\n",
        "\n",
        "# Verify that the current working directory has been changed\n",
        "print(os.getcwd())\n",
        "\n",
        "%cd /content/drive/MyDrive/Finetuning"
      ],
      "metadata": {
        "id": "c3vwxcDMzylE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "I0HQY-Gv_byW"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/hiyouga/LLaMA-Efficient-Tuning.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install bitsandbytes>=0.39.0\n",
        "!pip install -r /content/drive/MyDrive/Finetuning/LLaMA-Efficient-Tuning/requirements.txt\n",
        "!pip install trl==0.7.2"
      ],
      "metadata": {
        "id": "YFOcKtXnBBtE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/drive/MyDrive/Finetuning/.cache/huggingface/\""
      ],
      "metadata": {
        "id": "mEjE-ht2IdjE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficient_finetuning_folder = \"/content/drive/MyDrive/Finetuning/LLaMA-Efficient-Tuning\" #absolute path\n",
        "\n",
        "train_gpt_4 = \"train_gpt-4.json\"\n",
        "test = \"test.json\" # not the actual test set, but for a placeholder"
      ],
      "metadata": {
        "id": "jI1TYqdW_oZI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def add_json_file(efficient_finetuning_folder, json_file_name):\n",
        "    # Replace {username} with your actual username\n",
        "    data_info_file = f\"{efficient_finetuning_folder}/data/dataset_info.json\"\n",
        "\n",
        "    # Load the data_info.json file\n",
        "    with open(data_info_file, 'r') as f:\n",
        "        data_info = json.load(f)\n",
        "\n",
        "    # Create a new key by removing the .json extension from the file name\n",
        "    new_key = json_file_name.replace('.json', '')\n",
        "\n",
        "    # Add the new key to the data_info dictionary\n",
        "    data_info[new_key] = {\n",
        "        'file_name': json_file_name\n",
        "    }\n",
        "\n",
        "    # Save the updated data_info.json file\n",
        "    with open(data_info_file, 'w') as f:\n",
        "        json.dump(data_info, f, indent=4)\n",
        "\n",
        "    print(f'Added {new_key} to data_info.json')\n",
        "\n",
        "add_json_file(efficient_finetuning_folder, train_gpt_4)\n",
        "add_json_file(efficient_finetuning_folder, test)"
      ],
      "metadata": {
        "id": "EXTqhaOB_47s"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token ### HUGGINGFACE API KEY ###\n",
        "%cd /content/drive/MyDrive/Finetuning/LLaMA-Efficient-Tuning"
      ],
      "metadata": {
        "id": "9O9hWJsRpt7x"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FACT-GPT training"
      ],
      "metadata": {
        "id": "P_-i1Wh7fChN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_valid_llama(model_size, train_data):\n",
        "\n",
        "    command = f\"\"\"!CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/Finetuning/LLaMA-Efficient-Tuning/src/train_bash.py \\\n",
        "        --stage sft \\\n",
        "        --model_name_or_path \"meta-llama/Llama-2-{model_size}-chat-hf\" \\\n",
        "        --do_train \\\n",
        "        --dataset \"{train_data}\" \\\n",
        "        --template \"default\" \\\n",
        "        --finetuning_type \"lora\" \\\n",
        "        --lora_target \"q_proj,v_proj\" \\\n",
        "        --output_dir \"/content/drive/MyDrive/Finetuning/train_valid_{model_size}_{train_data}\" \\\n",
        "        --overwrite_cache \\\n",
        "        --per_device_train_batch_size 4 \\\n",
        "        --gradient_accumulation_steps 4 \\\n",
        "        --lr_scheduler_type \"cosine\" \\\n",
        "        --logging_steps 1 \\\n",
        "        --save_steps 61 \\\n",
        "        --val_size 0.2 \\\n",
        "        --evaluation_strategy steps \\\n",
        "        --eval_steps 61 \\\n",
        "        --learning_rate \"5e-5\" \\\n",
        "        --num_train_epochs 3.0 \\\n",
        "        --plot_loss True \\\n",
        "        --fp16\"\"\"\n",
        "\n",
        "    print(command)"
      ],
      "metadata": {
        "id": "30C-OeGJppHd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_llama(model_size, train_data):\n",
        "\n",
        "    command = f\"\"\"!CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\n",
        "    --stage sft \\\n",
        "    --model_name_or_path 'meta-llama/Llama-2-{model_size}-chat-hf' \\\n",
        "    --do_predict \\\n",
        "    --dataset 'test' \\\n",
        "    --template 'default' \\\n",
        "    --finetuning_type 'lora' \\\n",
        "    --checkpoint_dir '/content/drive/MyDrive/Finetuning/train_valid_{model_size}_{train_data}' \\\n",
        "    --output_dir '/content/drive/MyDrive/Finetuning/train_valid_{model_size}_{train_data}/test-endpoint' \\\n",
        "    --per_device_eval_batch_size 8 \\\n",
        "    --max_samples 10000 \\\n",
        "    --temperature 0.01 \\\n",
        "    --top_p 0.01 \\\n",
        "    --predict_with_generate\"\"\"\n",
        "\n",
        "    print(command)"
      ],
      "metadata": {
        "id": "Sgcn4h_HhAZM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "cm8mA078jA-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_valid_llama('13b', 'train_gpt-4')\n",
        "train_valid_llama('7b', 'train_gpt-4')"
      ],
      "metadata": {
        "id": "sbhjFzYKNIL3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/Finetuning/LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-13b-chat-hf\"         --do_train         --dataset \"train_gpt-4\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"/content/drive/MyDrive/Finetuning/train_valid_13b_train_gpt-4\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16\n",
        "!CUDA_VISIBLE_DEVICES=0 python /content/drive/MyDrive/Finetuning/LLaMA-Efficient-Tuning/src/train_bash.py         --stage sft         --model_name_or_path \"meta-llama/Llama-2-7b-chat-hf\"         --do_train         --dataset \"train_gpt-4\"         --template \"default\"         --finetuning_type \"lora\"         --lora_target \"q_proj,v_proj\"         --output_dir \"/content/drive/MyDrive/Finetuning/train_valid_7b_train_gpt-4\"         --overwrite_cache         --per_device_train_batch_size 4         --gradient_accumulation_steps 4         --lr_scheduler_type \"cosine\"         --logging_steps 1         --save_steps 61         --val_size 0.2         --evaluation_strategy steps         --eval_steps 61         --learning_rate \"5e-5\"         --num_train_epochs 3.0         --plot_loss True         --fp16"
      ],
      "metadata": {
        "id": "ByUalVn_jEBP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_llama('13b', 'train_gpt-4')\n",
        "test_llama('7b', 'train_gpt-4')"
      ],
      "metadata": {
        "id": "PIBKPRPHhMdr"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-13b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir '/content/drive/MyDrive/Finetuning/train_valid_13b_train_gpt-4'     --output_dir '/content/drive/MyDrive/Finetuning/train_valid_13b_train_gpt-4/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate\n",
        "!CUDA_VISIBLE_DEVICES=0 python src/train_bash.py     --stage sft     --model_name_or_path 'meta-llama/Llama-2-7b-chat-hf'     --do_predict     --dataset 'test'     --template 'default'     --finetuning_type 'lora'     --checkpoint_dir '/content/drive/MyDrive/Finetuning/train_valid_7b_train_gpt-4'     --output_dir '/content/drive/MyDrive/Finetuning/train_valid_7b_train_gpt-4/test-endpoint'     --per_device_eval_batch_size 8     --max_samples 10000     --temperature 0.01     --top_p 0.01     --predict_with_generate"
      ],
      "metadata": {
        "id": "NLH-47J6j_Yr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Put inference results into dataset"
      ],
      "metadata": {
        "id": "oOj8mJESaVeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/FACT-GPT dataset.csv')\n",
        "df['13b_finetuned_on_gpt_4'] = pd.read_json('/content/drive/MyDrive/Finetuning/train_valid_13b_train_gpt-4_balanced/test-endpoint/generated_predictions.jsonl', lines=True)['predict']\n",
        "df['13b_finetuned_on_gpt_3_5'] = pd.read_json('/content/drive/MyDrive/Finetuning/train_valid_13b_train_gpt-3_5_balanced/test-endpoint/generated_predictions.jsonl', lines=True)['predict']\n",
        "df['13b_finetuned_on_70b'] = pd.read_json('/content/drive/MyDrive/Finetuning/train_valid_13b_train_llama_2_70b_balanced/test-endpoint/generated_predictions.jsonl', lines=True)['predict']\n",
        "\n",
        "df['7b_finetuned_on_gpt_4'] = pd.read_json('/content/drive/MyDrive/Finetuning/train_valid_7b_train_gpt-4_balanced/test-endpoint/generated_predictions.jsonl', lines=True)['predict']\n",
        "df['7b_finetuned_on_gpt_3_5'] = pd.read_json('/content/drive/MyDrive/Finetuning/train_valid_7b_train_gpt-3_5_balanced/test-endpoint/generated_predictions.jsonl', lines=True)['predict']\n",
        "df['7b_finetuned_on_70b'] = pd.read_json('/content/drive/MyDrive/Finetuning/train_valid_7b_train_llama_2_70b_balanced/test-endpoint/generated_predictions.jsonl', lines=True)['predict']\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/FACT-GPT dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "_om-9ESzaaLa"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# unassign"
      ],
      "metadata": {
        "id": "hrVTXmemWmqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "q1e_ViyAd7Vq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}